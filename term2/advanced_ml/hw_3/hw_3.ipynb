{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47fd762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import random\n",
    "from typing import List, Tuple, Dict\n",
    "from textwrap import dedent\n",
    "from dataclasses import dataclass\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "471ee0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS1_RUS_PATH = \"data/WarAndPeace.txt\"\n",
    "CORPUS2_RUS_PATH = \"data/AnnaKarenina.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b8bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CORPUS1_RUS_PATH, mode=\"r\") as f1, open(CORPUS2_RUS_PATH, mode=\"r\") as f2:\n",
    "    part1 = f1.read()\n",
    "    part2 = f2.read()\n",
    "    corpus_rus = part1 + \" \" + part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857e4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mapping_unigrams(text: str, mapping: Dict[str, str]) -> str:\n",
    "    return \"\".join(mapping.get(s, s) for s in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ababe052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text:\n",
    "    def __init__(self, text: str) -> None:\n",
    "        text = self.preprocess(text)\n",
    "        self.decoded = text\n",
    "        self.encoded = self.encode(text)\n",
    "    \n",
    "    @staticmethod\n",
    "    def encode(text: str) -> Tuple[str, Dict[str, str], Dict[str, str]]:\n",
    "        chars = list(set(text))\n",
    "        shuffled_chars = random.sample(chars, k=len(chars))\n",
    "        encode_mapping = dict(zip(chars, shuffled_chars))\n",
    "        encoded_text = apply_mapping_unigrams(text, encode_mapping)\n",
    "        return encoded_text\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess(text: str) -> str:\n",
    "        text = re.sub(\"[^а-яА-ЯёЁ\\s]\", \" \", text)\n",
    "        text = text.replace(\"ё\", \"е\").replace(\"Ё\", \"е\")\n",
    "        text = \" \".join(text.split())\n",
    "        return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7b935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_chars_by_frequency_unigrams(text: str) -> List[str]:\n",
    "    return [s for s, _ in Counter(text).most_common()]\n",
    "\n",
    "def hamming_accuracy(text1: str, text2: str) -> float:\n",
    "    assert len(text1) == len(text2)\n",
    "    numerator = 0\n",
    "    for i in range(len(text1)):\n",
    "        if text1[i] == text2[i]:\n",
    "            numerator += 1\n",
    "    denominator = len(text1) or 1\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f578f",
   "metadata": {},
   "source": [
    "<b>\n",
    "1. Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "расшифруйте их таким частотным методом.\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc700b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_frequency_unigrams_translate(train_text: str, test_text: str) -> str:\n",
    "    train_text = Text.preprocess(train_text)\n",
    "    train_dictionary = sort_chars_by_frequency_unigrams(train_text)\n",
    "    \n",
    "    test_text = Text(test_text)\n",
    "    encoded_test_text = test_text.encoded\n",
    "    test_dictionary = sort_chars_by_frequency_unigrams(encoded_test_text)\n",
    "\n",
    "    mapping = dict(zip(test_dictionary, train_dictionary))\n",
    "    res = apply_mapping_unigrams(encoded_test_text, mapping)\n",
    "    score = hamming_accuracy(res, test_text.decoded)\n",
    "    print(f\"Hamming Accuracy: {score}\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da67b06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "corpus_rus = Text.preprocess(corpus_rus)\n",
    "\n",
    "assert corpus_rus == simple_frequency_unigrams_translate(corpus_rus, corpus_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a232a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = dedent(\"\"\"\n",
    "    В автобусе было душно и очень тесно. Старика зажали со всех сторон, и он уже сто раз пожалел о том, что \n",
    "    решил поехать на очередной прием к врачу ранним утром. Он ехал и думал о том, что совсем, казалось бы, \n",
    "    недавно, а на самом деле семьдесят лет тому назад, он ездил на автобусе в школу. А потом началась война. Он \n",
    "    не любил вспоминать то, что он пережил там. Больно было вспоминать тех, кто ушёл с ним добровольцем на фронт \n",
    "    и не вернулся. Война была для него и личной трагедией: во время боёв под Москвой и Сталинградом погибли его \n",
    "    отец и старший брат. Но был в его жизни один случай, который он тоже не мог забыть и простить себе. \n",
    "    Он ехал на автобусе в школу (он тогда учился в третьем классе), сел на последнее свободное место, \n",
    "    отвернувшись от старика, который беспомощно облокотился о поручень у дверей. Он не заметил, где сошёл старик,\n",
    "    но почему-то весь день потом вспоминал о нём, и острая поздняя боль раскаяния пронзила его душу. «Почему я \n",
    "    не уступил ему место?» – этот вопрос терзал день изо дня. Потом постепенно это воспоминание ушло на задний \n",
    "    план, но время от времени возвращалось как укол совести, как руководство к правильному поведению, к уважению \n",
    "    старших и поклону их опыту и седине. Теперь, когда он сам стал таким же немощным стариком, ему было до слёз \n",
    "    обидно, если он сталкивался с неуважительным отношением к людям пожилого возраста, к ветеранам. Автобус \n",
    "    остановился на остановке, пассажиры начали выходить, стоять стало свободнее. Вдруг к нему подошёл мальчик лет\n",
    "    десяти и сказал: «Садитесь, дедушка, на моё место, мне кажется, Вам тяжело стоять». У старика навернулись \n",
    "    слёзы на глаза. Это были одновременно и горькие, и сладкие слёзы. Они горчили потому, что совесть опять \n",
    "    напомнила случай семидесятилетней давности, но они радовали и согревали сердце потому, что он благодаря этому\n",
    "    мальчику верил, что не всё потеряно для русского человека. \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "355d111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Accuracy: 0.6233333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'в авиогмте гчло дмжно с оыеня иетно тиаксуа башалс то втех тиокон с он мше тио каб пошалел о иор ыио кежсл поехаия на оыекедной пксер у вкаым каннср микор он ехал с дмрал о иор ыио товтер уабалотя гч недавно а на тарор деле терядетьи леи иорм набад он ебдсл на авиогмте в жуолм а поиор наыалатя война он не люгсл втпорснаия ио ыио он пекешсл иар голяно гчло втпорснаия иех уио мжел т нср догковоляцер на фкони с не векнмлть война гчла дль незо с лсыной иказедсей во вкерь гоев под ротувой с тиалснзкадор позсглс езо оиец с тиакжсй гкаи но гчл в езо шсбнс одсн тлмыай уоиокчй он иоше не роз багчия с пкотисия теге он ехал на авиогмте в жуолм он иозда мыслть в икеияер улатте тел на потледнее твогодное ретио оивекнмвжстя ои тиаксуа уоиокчй гетпорощно оглоуоислть о покмыеня м двекей он не бареисл зде тожел тиаксу но поыерм ио ветя деня поиор втпорснал о нер с отикаь побдньь голя катуаьнсь пконбсла езо дмжм поыерм ь не мтимпсл ерм ретио эиои вопкот иекбал деня сбо днь поиор потиепенно эио вотпорснансе мжло на баднсй план но вкерь ои вкеренс вобвкащалотя уау муол товетис уау кмуоводтиво у пкавслянорм поведенсю у мвашенсю тиакжсх с поулонм сх опчим с тедсне иепекя уозда он тар тиал иауср ше нерощнчр тиаксуор ерм гчло до тлеб огсдно етлс он тиалусвалть т немвашсиелянчр оиноженсер у людьр пошслозо вобкатиа у веиеканар авиогмт отиановслть на отиановуе патташскч наыалс вчходсия тиоьия тиало твогоднее вдкмз у нерм подожел раляысу леи детьис с туабал тадсиетя дедмжуа на рое ретио рне уашеить вар иьшело тиоьия м тиаксуа навекнмлстя тлебч на злаба эио гчлс одновкеренно с зокяусе с тладусе тлебч онс зокыслс поиорм ыио товетия опьия напорнсла тлмыай терсдетьислеиней давнотис но онс кадовалс с тозкевалс текдце поиорм ыио он глазодакь эиорм раляысум вексл ыио не вте поиекьно дль кмттуозо ыеловеуа'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_frequency_unigrams_translate(corpus_rus, test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f779be65",
   "metadata": {},
   "source": [
    "<i><strong>\n",
    "Был взят достаточно большой текст, и в целом получилось неплохо по метрике (выше ожиданий), но все-таки нечитаемо.\n",
    "</strong></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20cfca4",
   "metadata": {},
   "source": [
    "<b>\n",
    "2. Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "проведите тестирование аналогично п.1, но при помощи биграмм.\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a40a7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams(text: str) -> List[str]:\n",
    "    return [text[i:i + 2] for i in range(0, len(text) - 1, 2)]\n",
    "\n",
    "\n",
    "def sort_chars_by_frequency_bigrams(text: str) -> List[str]:\n",
    "    bigrams = get_bigrams(text)\n",
    "    return [s for s, _ in Counter(bigrams).most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a62a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mapping_bigrams(text: str, mapping: Dict[str, str]) -> str:\n",
    "    res = \"\".join([\n",
    "        mapping.get(text[i:i + 2], text[i:i + 2])\n",
    "        for i in range(0, len(text) - 1, 2)\n",
    "    ])\n",
    "    return res\n",
    "\n",
    "\n",
    "def simple_frequency_bigrams_translate(train_text: str, test_text: str) -> str:\n",
    "    train_text = Text.preprocess(train_text)\n",
    "    train_dictionary = sort_chars_by_frequency_bigrams(train_text)\n",
    "    \n",
    "    test_text = Text(test_text)\n",
    "    encoded_test_text = test_text.encoded\n",
    "    test_dictionary = sort_chars_by_frequency_bigrams(encoded_test_text)\n",
    "\n",
    "    mapping = dict(zip(test_dictionary, train_dictionary))\n",
    "    mapped = apply_mapping_bigrams(encoded_test_text, mapping)\n",
    "    if len(mapped) != len(test_text.decoded):\n",
    "        mapped += \" \"\n",
    "    score = hamming_accuracy(mapped, test_text.decoded)\n",
    "    print(f\"Hamming Accuracy: {score}\")\n",
    "    return mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cc75a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "assert corpus_rus == simple_frequency_bigrams_translate(corpus_rus, corpus_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84b15e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Accuracy: 0.08888888888888889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'сь уа мениколие изсае  иннла о миче наорил врадр до е рит о а аз к им варео а бых ал э чим сенонзаа быудкаалмишин и  вннвокинеже гемя  едеужгороикднвамуон с кт  чпоовид ч сенонзаа о инния  брал такоестьэтиве  всто тионовим пниглиттеоломола ски х ек с кмаань сттраматве псьокасго в на я стаяу татодост с ктьслочкатокронку х оа заа  с ктык нуь ноя еты неколие ри негстн ент й а ваодь выотя лесиинасих ти  вжим ол итьтовольтвпрелжа вруу овейи еде  и дятдоенротуанийтое де тпретчиалакылеррыдопоо но дщеролея  нвнсо иеде осыйпоо ноиеаркороолнеколито зоееписот сан квию  жй осседи с ка реи  п лымрарун поалазнаше ониош с кт  чи  в уа менитомноглс с ка вс вю катетоенк н  тй у хо пниь сталеромв чао елетв миылоба  севвольулпе оосо нонь бй осседикооб н лебе атл огдатвпре  надчтлуваовлок жем и  прачедаь вс пмоодь наорили е  нчтскене лотаовла о на я ри негсть е тья  иермуняалажв пакоас оро яняотпр гм ьку  зоеовойго нчтскбри  пвеутвшь  тгоченае боостоавазвы мз  човла оисе в пр на я  ннабеланеееа тоер негстот пойл и  врав аралу  кнеток ез солде тла иелусроумл тай ьнваогь молона и б еадогелгдеве  е г укаопонго нлоитоткн еугзнлатно ноиеувпоалбул льпожнавшаго иниантьенбево оогвс вм о тио ноь нод я реи  таесвя наорилон зскколие лео омлыатдуне зви им о ноывиц чтео и ую рну мы свя оснеодот тй сллюыеал эка ае елозечной тоожволятитраматве сналяинкатеи  вернонеря пбахозннсесстая дтоахакше онагрн о нол о елетв чатогаврй и  тго нлеодь ияы ся еомолиттедапоо  браь снан мтаовкиой би  в л пченае сп п бреяспр ря ялрел о а с  огонаорил встлосмехпе овимаесстныу раееа коли иакнеде тланепонысеешемпоо у хаемо омьс сотнысеся далосонгорье молона оавс  ост нспка ввию  жо  тдуобс каожтьжеэтивердаи е м  ироле р дпоо  ак  р до водв п на скзаа  с ксоыхакорпрбоонгоияы сяуктовоказаа и  при п н ммынеовейбыве я ае чтл ло б'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_frequency_bigrams_translate(corpus_rus, test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188aaca9",
   "metadata": {},
   "source": [
    "<i><strong>\n",
    "Неудивительно, что результат хуже, ведь для \"правильного\" ранжирования биграмм необходим куда больший тестовый корпус, в виду их большего разнообразия по сравнению с юниграммами.\n",
    "</strong></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2f5fc4",
   "metadata": {},
   "source": [
    "<b>\n",
    "3. Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e63cb489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_bigrams(text: str) -> List[str]:\n",
    "    return [text[i:i + 2] for i in range(len(text) - 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f271ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freqs(text: str) -> Dict[str, float]:\n",
    "    bigrams = get_all_bigrams(text)\n",
    "    freqs = {}\n",
    "    for k, v in Counter(bigrams).items():\n",
    "        freqs[k] = v / len(bigrams)\n",
    "    return freqs\n",
    "\n",
    "def text_proba(text: str, mapping: Dict[str, str], freqs: Dict[str, float]) -> float:\n",
    "    decoded_text = apply_mapping_unigrams(text, mapping)\n",
    "    bigrams = get_all_bigrams(decoded_text)\n",
    "    log_proba = 0\n",
    "    for b in bigrams:\n",
    "        log_proba += np.log(freqs.get(b, 1 / len(bigrams)))\n",
    "    return log_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "042e34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MCMC:\n",
    "    train_text: str\n",
    "    test_text: str\n",
    "    num_iterations: int = 10000\n",
    "    num_epochs: int = 10\n",
    "    verbose: bool = False\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.best_mapping = None\n",
    "        self.best_log_proba = -np.inf\n",
    "        self.train_alphabet = list(set(self.train_text))\n",
    "        self.test_alphabet = list(set(self.test_text))\n",
    "        self.train_freqs = get_freqs(self.train_text)\n",
    "    \n",
    "    def fit(self):\n",
    "        for e in trange(self.num_epochs):\n",
    "            cur_mapping = self.get_mapping(self.test_alphabet, self.train_alphabet)\n",
    "            cur_log_proba = text_proba(self.test_text, cur_mapping, self.train_freqs)\n",
    "            trained_alphabet = self.train_alphabet[:]\n",
    "            \n",
    "            for i in tqdm(range(self.num_iterations), leave=False):\n",
    "                proposal_alphabet = self.transposition(trained_alphabet)\n",
    "                proposal_mapping = self.get_mapping(self.test_alphabet, proposal_alphabet)\n",
    "                proposal_log_proba = text_proba(self.test_text, proposal_mapping, self.train_freqs)\n",
    "                \n",
    "                p_proba = np.clip(np.exp(proposal_log_proba - cur_log_proba), 0, 1)\n",
    "                \n",
    "                if p_proba > random.random():\n",
    "                    cur_log_proba = proposal_log_proba\n",
    "                    cur_mapping = proposal_mapping\n",
    "                    trained_alphabet = proposal_alphabet[:]\n",
    "                    \n",
    "            if cur_log_proba > self.best_log_proba:\n",
    "                self.best_log_proba = cur_log_proba\n",
    "                self.best_mapping = cur_mapping\n",
    "            print(f\"Epoch: {e}, Log-likelihood: {self.best_log_proba}\")\n",
    "            if self.verbose:\n",
    "                print()\n",
    "                self.inference()\n",
    "                \n",
    "    def inference(self):\n",
    "        res = apply_mapping_unigrams(self.test_text, self.best_mapping)\n",
    "        print(res)\n",
    "        \n",
    "    @staticmethod\n",
    "    def transposition(alphabet):\n",
    "        res = alphabet[:]\n",
    "        idx1, idx2 = np.random.choice(len(res), size=2, replace=False)\n",
    "        res[idx1], res[idx2] = res[idx2], res[idx1]\n",
    "        return res\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mapping(alphabet1, alphabet2):\n",
    "        return dict(zip(alphabet1, alphabet2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bef7330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "жвижуйестзвеомйвясцлйвнвйбзльвузтлйвтуиандивкихимнвтйвжтзрвтуйайлвнвйлвсхзвтуйваиквюйхимзмвйвуй вбуйвазцнмвюйзриуьвливйбзазялйщвюанз вдвжаибсваиллн всуай вйлвзримвнвяс имвйвуй вбуйвтйжтз вдикимйтьвеовлзяижлйвивливти й вязмзвтз ьязтпувмзувуй свликиявйлвзкянмвливижуйестзвжвцдймсвивюйуй влибимитьвжйщливйлвлзвмгенмвжтюй нлиуьвуйвбуйвйлвюзазхнмвуи веймьлйвеомйвжтюй нлиуьвузрвдуйвсцзмвтвлн вяйеайжймьфз вливэайлувнвлзвжзалсмтпвжйщливеомивямпвлзыйвнвмнблйщвуаиызянзщвжйвжаз пвейзжвюйяв йтджйщвнвтуимнлыаияй вюйынемнвзыйвйузфвнвтуиацнщвеаиувлйвеомвжвзыйвхнклнвйянлвтмсбищвдйуйаощвйлвуйхзвлзв йывкиеоуьвнвюайтунуьвтзезвйлвзримвливижуйестзвжвцдймсвйлвуйыяивсбнмтпвжвуазуьз вдмиттзвтзмвливюйтмзялззвтжйейялйзв зтуйвйужзалсжцнтьвйувтуиандивдйуйаощвезтюй йшлйвйемйдйунмтпвйвюйасбзльвсвяжзазщвйлвлзвки зунмвыязвтйцзмвтуиандвлйвюйбз свуйвжзтьвязльвюйуй вжтюй нлимвйвлз внвйтуаипвюйкялппвеймьваитдиплнпвюайлкнмивзыйвясцсвюйбз свпвлзвстусюнмвз св зтуйвчуйувжйюайтвузакимвязльвнкйвялпвюйуй вюйтузюзллйвчуйвжйтюй нлилнзвсцмйвливкиялнщвюмилвлйвжаз пвйувжаз злнвжйкжаишимйтьвдидвсдймвтйжзтунвдидвасдйжйятужйвдвюаижнмьлй свюйжзязлнгвдвсжихзлнгвтуиацнрвнвюйдмйлсвнрвйюоусвнвтзянлзвузюзаьвдйыяивйлвти втуимвуидн вхзвлз йшло втуиандй вз свеомйвяйвтмзквйенялйвзтмнвйлвтуимднжимтпвтвлзсжихнузмьло вйулйцзлнз вдвмгяп вюйхнмйыйвжйкаитуивдвжзузаили вижуйествйтуилйжнмтпвливйтуилйждзвюиттихнаовлибимнвжорйянуьвтуйпуьвтуимйвтжйейялззвжяасывдвлз свюйяйцзмв имьбндвмзувязтпунвнвтдикимвтиянузтьвязясцдивлив йзв зтуйв лзвдихзутпвжи вупхзмйвтуйпуьвсвтуиандивлижзалсмнтьвтмзковливымикивчуйвеомнвйялйжаз зллйвнвыйаьднзвнвтмияднзвтмзковйлнвыйабнмнвюйуй свбуйвтйжзтуьвйюпуьвлиюй лнмивтмсбищвтз нязтпунмзулзщвяижлйтунвлйвйлнваияйжимнвнвтйыазжимнвтзаяфзвюйуй свбуйвйлвемиыйяиапвчуй св имьбндсвжзанмвбуйвлзвжтзвюйузаплйвямпвасттдйыйвбзмйжзди\n"
     ]
    }
   ],
   "source": [
    "encoded_text = Text(test_text).encoded\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd9c8f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f386e5000e741559a26be20df52270f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Log-likelihood: -9656.335559151188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Log-likelihood: -9656.335559151188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-351ff23d354c>:27: RuntimeWarning: overflow encountered in exp\n",
      "  p_proba = np.clip(np.exp(proposal_log_proba - cur_log_proba), 0, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Log-likelihood: -9656.335559151188\n"
     ]
    }
   ],
   "source": [
    "mcmc = MCMC(corpus_rus, encoded_text, num_epochs=3, num_iterations=10000)\n",
    "\n",
    "mcmc.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b89137ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в автобусе было душно и очень тесно старика зажали со всех сторон и он уже сто раз пожалел о том что решил поехать на очередной прием к врачу ранним утром он ехал и думал о том что совсем казалось бы недавно а на самом деле семьдесят лет тому назад он ездил на автобусе в школу а потом началась война он не любил вспоминать то что он пережил там больно было вспоминать тех кто ушел с ним добровольцем на фронт и не вернулся война была для него и личной трагедией во время боев под москвой и сталинградом погибли его отец и старший брат но был в его жизни один случай который он тоже не мог забыть и простить себе он ехал на автобусе в школу он тогда учился в третьем классе сел на последнее свободное место отвернувшись от старика который беспомоъно облокотился о поручень у дверей он не заметил где сошел старик но почему то весь день потом вспоминал о нем и острая поздняя боль раскаяния пронзила его душу почему я не уступил ему место этот вопрос терзал день изо дня потом постепенно это воспоминание ушло на задний план но время от времени возвраъалось как укол совести как руководство к правильному поведению к уважению старших и поклону их опыту и седине теперь когда он сам стал таким же немоъным стариком ему было до слез обидно если он сталкивался с неуважительным отношением к людям пожилого возраста к ветеранам автобус остановился на остановке пассажиры начали выходить стоять стало свободнее вдруг к нему подошел мальчик лет десяти и сказал садитесь дедушка на мое место мне кажется вам тяжело стоять у старика навернулись слезы на глаза это были одновременно и горькие и сладкие слезы они горчили потому что совесть опять напомнила случай семидесятилетней давности но они радовали и согревали сердце потому что он благодаря этому мальчику верил что не все потеряно для русского человека\n"
     ]
    }
   ],
   "source": [
    "mcmc.inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b710dd01",
   "metadata": {},
   "source": [
    "<b>\n",
    "4. Расшифруйте сообщение:\n",
    "←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22b93dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_message = \"←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfd20e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ecefa024f3448d898cde62e0b60e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Log-likelihood: -1307.5529872387574\n",
      "\n",
      "нъитйжпйжтотанй чщылим прйтитйэчяатй чщылим прйануъайхйьачцчйъччден твйучачщпрйинцучйэщчяталамйъучщннйжънцчйжпйжънйъонилитйэщлжтим чйтйэчихятанйылуътылим прйдлиийглйэчъино ннйянажнщачнйглол тнйухщълйючавйуч ня чйвй тянцчй нйчднелф\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Log-likelihood: -1299.9407936684152\n",
      "\n",
      "йьногхзгхосолйгпъшжен пзфгоногцъвлогпъшжен пзфглйыьлгагилъуъгьъъщюйпочгыълъшзфгнйуыъгцшъволел гьыъшййгхьйуъгхзгхьйгьсйненогцшехон пъгогцънаволйгжеыьожен пзфгщеннгэегцъьнйспййгвйлхйшлъйгэесепойгыашьегяълчгыъпйвпъгчгповйуъгпйгъщйюеб\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Log-likelihood: -1299.9407936684152\n",
      "\n",
      "йьногхзгхосолйгпъшжен пзфгоногцъвлогпъшжен пзфглйыьлгагилъуъгьъъщюйпочгыълъшзфгнйуыъгцшъволел гьыъшййгхьйуъгхзгхьйгьсйненогцшехон пъгогцънаволйгжеыьожен пзфгщеннгэегцъьнйспййгвйлхйшлъйгэесепойгыашьегяълчгыъпйвпъгчгповйуъгпйгъщйюеб\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Log-likelihood: -1299.9407936684152\n",
      "\n",
      "йьногхзгхосолйгпъшжен пзфгоногцъвлогпъшжен пзфглйыьлгагилъуъгьъъщюйпочгыълъшзфгнйуыъгцшъволел гьыъшййгхьйуъгхзгхьйгьсйненогцшехон пъгогцънаволйгжеыьожен пзфгщеннгэегцъьнйспййгвйлхйшлъйгэесепойгыашьегяълчгыъпйвпъгчгповйуъгпйгъщйюеб\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Log-likelihood: -1299.9407936684152\n",
      "\n",
      "йьногхзгхосолйгпъшжен пзфгоногцъвлогпъшжен пзфглйыьлгагилъуъгьъъщюйпочгыълъшзфгнйуыъгцшъволел гьыъшййгхьйуъгхзгхьйгьсйненогцшехон пъгогцънаволйгжеыьожен пзфгщеннгэегцъьнйспййгвйлхйшлъйгэесепойгыашьегяълчгыъпйвпъгчгповйуъгпйгъщйюеб\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Log-likelihood: -1299.9407936684152\n",
      "\n",
      "йьногхзгхосолйгпъшжен пзфгоногцъвлогпъшжен пзфглйыьлгагилъуъгьъъщюйпочгыълъшзфгнйуыъгцшъволел гьыъшййгхьйуъгхзгхьйгьсйненогцшехон пъгогцънаволйгжеыьожен пзфгщеннгэегцъьнйспййгвйлхйшлъйгэесепойгыашьегяълчгыъпйвпъгчгповйуъгпйгъщйюеб\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Log-likelihood: -1210.2653009748797\n",
      "\n",
      "если чы читине воъзалйвыь или подни воъзалйвыь нексн у жноро соошэевия коноъыь лерко пъодинанй скоъее чсеро чы чсе стелали пъачилйво и полудине заксизалйвыь шалл ма послетвее денчеъное матавие куъса гоня коведво я видеро ве ошеэащ\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Log-likelihood: -1210.2653009748797\n",
      "\n",
      "если чы читине воъзалйвыь или подни воъзалйвыь нексн у жноро соошэевия коноъыь лерко пъодинанй скоъее чсеро чы чсе стелали пъачилйво и полудине заксизалйвыь шалл ма послетвее денчеъное матавие куъса гоня коведво я видеро ве ошеэащ\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Log-likelihood: -1210.2653009748797\n",
      "\n",
      "если чы читине воъзалйвыь или подни воъзалйвыь нексн у жноро соошэевия коноъыь лерко пъодинанй скоъее чсеро чы чсе стелали пъачилйво и полудине заксизалйвыь шалл ма послетвее денчеъное матавие куъса гоня коведво я видеро ве ошеэащ\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Log-likelihood: -1210.2653009748797\n",
      "\n",
      "если чы читине воъзалйвыь или подни воъзалйвыь нексн у жноро соошэевия коноъыь лерко пъодинанй скоъее чсеро чы чсе стелали пъачилйво и полудине заксизалйвыь шалл ма послетвее денчеъное матавие куъса гоня коведво я видеро ве ошеэащ\n"
     ]
    }
   ],
   "source": [
    "mcmc = MCMC(corpus_rus, encoded_message, num_epochs=10, num_iterations=1000000, verbose=True)\n",
    "\n",
    "mcmc.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674f8ff1",
   "metadata": {},
   "source": [
    "<i><strong>\n",
    "Текст прочитать можно, но есть неточности\n",
    "</strong></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
